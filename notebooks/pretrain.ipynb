{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ba85ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d469c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.NN.KerasMultiHead import MultiHeadModel\n",
    "from src.Data.IMULocationDataset import IMULocationDataset\n",
    "from src.Data.MergedIMULocationDataset import MergedIMULocationDataset\n",
    "from whar_datasets import WHARDatasetID\n",
    "from src.NN.Arch.ClassifierHead import *\n",
    "from src.NN.Arch.ReconstructionHead import *\n",
    "from src.NN.Arch.Encoder import *\n",
    "from src.Data.SensorTypes import SensorLocation\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7613fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded IMU Dataset from cache.\n",
      "Loaded IMU Dataset from cache.\n",
      "Loaded IMU Dataset from cache.\n"
     ]
    }
   ],
   "source": [
    "mhealth = IMULocationDataset(WHARDatasetID.MHEALTH)\n",
    "dsads = IMULocationDataset(WHARDatasetID.DSADS)\n",
    "pamap2 = IMULocationDataset(WHARDatasetID.PAMAP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9846b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = MergedIMULocationDataset([mhealth, dsads], locations=[SensorLocation.ARMS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da766b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 10 12 13 15 18 19 20 21 22 24 26 32 36 37 38 40 43 44 51 52 55 56\n",
      " 57]\n"
     ]
    }
   ],
   "source": [
    "merged_dataset.train.samples.shape\n",
    "ds_slice = merged_dataset.train.samples[0:5, :, :]\n",
    "\n",
    "print(np.unique(merged_dataset.train.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78166e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone parameters: 287634\n",
      "Classifier head parameters: 7611\n",
      "Epoch 1/5\n",
      "\u001b[1m1270/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.5000 - loss: 1.7145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 15:04:08.026585: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 20ms/step - acc: 0.5874 - loss: 1.3158\n",
      "Epoch 2/5\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - acc: 0.7007 - loss: 0.9027\n",
      "Epoch 3/5\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - acc: 0.7372 - loss: 0.7754\n",
      "Epoch 4/5\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - acc: 0.7667 - loss: 0.6878\n",
      "Epoch 5/5\n",
      "\u001b[1m1275/1275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - acc: 0.7847 - loss: 0.6278\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras import layers as L\n",
    "\n",
    "\n",
    "backbone = build_conv_backbone_seq(ts_len=merged_dataset.train.samples.shape[1])\n",
    "classifier_head = build_classifier_head(num_classes=merged_dataset.num_classes, channels=backbone.output_shape[-1])\n",
    "backbone(ds_slice).shape\n",
    "print(\"Backbone parameters:\", backbone.count_params())\n",
    "print(\"Classifier head parameters:\", classifier_head.count_params())\n",
    "\n",
    "multi_head = MultiHeadModel(backbone)\n",
    "multi_head.add_head(\"classifier\", classifier_head)\n",
    "multi_head(ds_slice)[\"classifier\"].shape\n",
    "\n",
    "multi_head.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0),\n",
    "    loss={\"classifier\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={\"classifier\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]},\n",
    ")\n",
    "\n",
    "history = multi_head.fit(x=merged_dataset.train.samples, y={\"classifier\": merged_dataset.train.labels}, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd610182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_classifier_head(num_classes):\n",
    "#     z_in = tf.keras.Input(shape=(128,), name=\"embedding\")\n",
    "#     x = L.Dense(64, activation=\"swish\", name=\"clf_dense1\")(z_in)\n",
    "#     x = L.Dropout(0.3, name=\"clf_do1\")(x)\n",
    "#     x = L.Dense(num_classes, activation=\"softmax\", name=\"clf_out\")(x)\n",
    "#     return tf.keras.Model(z_in, x, name=\"classifier_head\")\n",
    "\n",
    "# classifier_head = build_classifier_head(num_classes=dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1821b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 15:15:17.005460: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 12.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2026-01-09 15:15:17.027936: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 40ms/step - loss: 0.1410 - val_loss: 0.1242\n",
      "Epoch 2/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1211 - val_loss: 0.1189\n",
      "Epoch 3/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1181 - val_loss: 0.1167\n",
      "Epoch 4/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1161 - val_loss: 0.1150\n",
      "Epoch 5/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1152 - val_loss: 0.1141\n",
      "Epoch 6/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1139 - val_loss: 0.1134\n",
      "Epoch 7/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1133 - val_loss: 0.1120\n",
      "Epoch 8/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1125 - val_loss: 0.1123\n",
      "Epoch 9/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1116 - val_loss: 0.1106\n",
      "Epoch 10/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1116 - val_loss: 0.1107\n",
      "Epoch 11/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1110 - val_loss: 0.1096\n",
      "Epoch 12/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1104 - val_loss: 0.1094\n",
      "Epoch 13/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1104 - val_loss: 0.1091\n",
      "Epoch 14/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1098 - val_loss: 0.1084\n",
      "Epoch 15/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1093 - val_loss: 0.1089\n",
      "Epoch 16/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1090 - val_loss: 0.1079\n",
      "Epoch 17/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1092 - val_loss: 0.1083\n",
      "Epoch 18/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1088 - val_loss: 0.1077\n",
      "Epoch 19/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1084 - val_loss: 0.1073\n",
      "Epoch 20/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1084 - val_loss: 0.1071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x76ff5e932bd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.Data.Preprocessing import make_masked_reconstruction_ds\n",
    "\n",
    "multi_head.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3, clipnorm=1.0),\n",
    "    loss={\"reconstruction\": tf.keras.losses.MeanSquaredError()},\n",
    ")\n",
    "\n",
    "train_ds = make_masked_reconstruction_ds(merged_dataset.train.samples, batch_size=64, mask_ratio=0.2)\n",
    "val_ds   = make_masked_reconstruction_ds(merged_dataset.val.samples,   batch_size=64, mask_ratio=0.2, shuffle=0)\n",
    "\n",
    "multi_head.fit(train_ds, validation_data=val_ds, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f27b8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head.backbone.save(\"pretrained_backbone.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65fce3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_dataset = MergedIMULocationDataset([dsads, mhealth], locations=[SensorLocation.ARMS], ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7e136f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 75ms/step - acc: 0.2832 - loss: 2.7781 - val_acc: 0.4279 - val_loss: 1.9596\n",
      "Epoch 2/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.4272 - loss: 1.8920 - val_acc: 0.4998 - val_loss: 1.6652\n",
      "Epoch 3/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.4941 - loss: 1.6823 - val_acc: 0.5466 - val_loss: 1.5205\n",
      "Epoch 4/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.5265 - loss: 1.5407 - val_acc: 0.5646 - val_loss: 1.4314\n",
      "Epoch 5/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.5615 - loss: 1.4600 - val_acc: 0.5947 - val_loss: 1.3658\n",
      "Epoch 6/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.5647 - loss: 1.4009 - val_acc: 0.5867 - val_loss: 1.3285\n",
      "Epoch 7/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.5866 - loss: 1.3517 - val_acc: 0.5981 - val_loss: 1.2900\n",
      "Epoch 8/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.5900 - loss: 1.3273 - val_acc: 0.6137 - val_loss: 1.2615\n",
      "Epoch 9/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.5988 - loss: 1.2860 - val_acc: 0.6182 - val_loss: 1.2332\n",
      "Epoch 10/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6057 - loss: 1.2569 - val_acc: 0.6288 - val_loss: 1.2081\n",
      "Epoch 11/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6074 - loss: 1.2374 - val_acc: 0.6297 - val_loss: 1.1960\n",
      "Epoch 12/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6091 - loss: 1.2283 - val_acc: 0.6327 - val_loss: 1.1838\n",
      "Epoch 13/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6170 - loss: 1.2122 - val_acc: 0.6422 - val_loss: 1.1622\n",
      "Epoch 14/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6224 - loss: 1.1963 - val_acc: 0.6502 - val_loss: 1.1508\n",
      "Epoch 15/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6287 - loss: 1.1895 - val_acc: 0.6522 - val_loss: 1.1363\n",
      "Epoch 16/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6280 - loss: 1.1661 - val_acc: 0.6452 - val_loss: 1.1323\n",
      "Epoch 17/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6307 - loss: 1.1549 - val_acc: 0.6537 - val_loss: 1.1201\n",
      "Epoch 18/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6258 - loss: 1.1547 - val_acc: 0.6558 - val_loss: 1.1082\n",
      "Epoch 19/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6435 - loss: 1.1388 - val_acc: 0.6564 - val_loss: 1.1065\n",
      "Epoch 20/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6417 - loss: 1.1258 - val_acc: 0.6601 - val_loss: 1.0959\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "classifier_head = build_classifier_head(\n",
    "    num_classes=merged_dataset.num_classes,\n",
    "    channels=multi_head.backbone.output_shape[-1],\n",
    ")\n",
    "\n",
    "multi_head = MultiHeadModel(keras.models.load_model(\"pretrained_backbone.keras\"))\n",
    "\n",
    "\n",
    "multi_head.add_head(\"classifier\", classifier_head)\n",
    "# multi_head.backbone.trainable = False\n",
    "\n",
    "multi_head.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3, clipnorm=1.0),\n",
    "    loss={\"classifier\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={\"classifier\": [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]},\n",
    ")\n",
    "\n",
    "history = multi_head.fit(\n",
    "    x=fine_tune_dataset.train.samples,\n",
    "    y={\"classifier\": fine_tune_dataset.train.labels},\n",
    "    validation_data=(fine_tune_dataset.val.samples, {\"classifier\": fine_tune_dataset.val.labels}),\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0760f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mVisualization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtsne\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tsne, plot_tsne\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.Visualization.tsne import tsne, plot_tsne\n",
    "import numpy as np\n",
    "import keras\n",
    "keras.models.load_model(\"pretrained_backbone.keras\")\n",
    "\n",
    "# If your backbone outputs (N,T,C), pool to (N,C) first:\n",
    "feat = backbone.predict(merged_dataset.train.samples, batch_size=32, verbose=1).numpy()   # (N,T,C)\n",
    "E = feat.mean(axis=1)\n",
    "print(E.shape)\n",
    "\n",
    "# res = tsne(E, perplexity=30, random_state=0)\n",
    "# plot_tsne(res.xy, labels=merged_dataset.val.labels, title=\"Backbone embeddings (val)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a6961",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyharfoundation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
